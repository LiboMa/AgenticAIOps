"""
Incident Orchestrator â€” Step 4 Closed-Loop Integration

Ties together Step 1 (Data Collection) â†’ Step 2 (RCA Inference) â†’ 
Step 3 (Safety Layer) â†’ SOP Execution into a single automated pipeline.

Flow:
  Alert/Trigger â†’ Collect â†’ Analyze â†’ Match SOP â†’ Safety Check â†’ Execute â†’ Learn
       â†‘                                                              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Feedback Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Trigger types:
  - CloudWatch Alarm (auto)
  - Anomaly Detection (auto)
  - Health Event (auto)
  - Manual chat command (user)

Design ref: docs/designs/SOP_RCA_ENHANCEMENT_DESIGN.md
"""

import asyncio
import logging
import time
import uuid
from datetime import datetime, timezone
from typing import Optional, Dict, Any, List
from dataclasses import dataclass, field, asdict
from enum import Enum

logger = logging.getLogger(__name__)


class TriggerType(Enum):
    ALARM = "alarm"
    ANOMALY = "anomaly"
    HEALTH_EVENT = "health_event"
    MANUAL = "manual"
    PROACTIVE = "proactive"
    DETECT_AGENT = "detect_agent"


class IncidentStatus(Enum):
    TRIGGERED = "triggered"
    COLLECTING = "collecting"
    ANALYZING = "analyzing"
    SOP_MATCHED = "sop_matched"
    SAFETY_CHECK = "safety_check"
    EXECUTING = "executing"
    WAITING_APPROVAL = "waiting_approval"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class IncidentRecord:
    """Full lifecycle record of an incident through the pipeline."""
    incident_id: str
    trigger_type: TriggerType
    trigger_data: Dict[str, Any]
    region: str
    status: IncidentStatus = IncidentStatus.TRIGGERED
    
    # Pipeline results
    collection_summary: Optional[Dict[str, Any]] = None
    rca_result: Optional[Dict[str, Any]] = None
    matched_sops: Optional[List[Dict[str, Any]]] = None
    safety_check: Optional[Dict[str, Any]] = None
    execution_result: Optional[Dict[str, Any]] = None
    
    # Timing
    created_at: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    completed_at: Optional[str] = None
    duration_ms: int = 0
    stage_timings: Dict[str, int] = field(default_factory=dict)
    
    # Errors
    error: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        d = asdict(self)
        d['trigger_type'] = self.trigger_type.value
        d['status'] = self.status.value
        return d
    
    def to_markdown(self) -> str:
        """Generate markdown incident report."""
        status_icon = {
            IncidentStatus.TRIGGERED: "ğŸ””",
            IncidentStatus.COLLECTING: "ğŸ“¡",
            IncidentStatus.ANALYZING: "ğŸ§ ",
            IncidentStatus.SOP_MATCHED: "ğŸ”",
            IncidentStatus.SAFETY_CHECK: "ğŸ›¡ï¸",
            IncidentStatus.EXECUTING: "âš¡",
            IncidentStatus.WAITING_APPROVAL: "ğŸ”",
            IncidentStatus.COMPLETED: "âœ…",
            IncidentStatus.FAILED: "âŒ",
        }.get(self.status, "â“")
        
        md = f"""## {status_icon} äº‹ä»¶ `{self.incident_id[:12]}`

| å±æ€§ | å€¼ |
|------|-----|
| è§¦å‘ç±»å‹ | {self.trigger_type.value} |
| çŠ¶æ€ | {self.status.value} |
| åŒºåŸŸ | {self.region} |
| æ€»è€—æ—¶ | {self.duration_ms}ms |
| æ—¶é—´ | {self.created_at} |
"""
        # Stage timings
        if self.stage_timings:
            md += "\n### â±ï¸ å„é˜¶æ®µè€—æ—¶\n\n"
            md += "| é˜¶æ®µ | è€—æ—¶ |\n|------|------|\n"
            for stage, ms in self.stage_timings.items():
                md += f"| {stage} | {ms}ms |\n"
        
        # RCA Result
        if self.rca_result:
            rca = self.rca_result
            sev = rca.get('severity', 'unknown')
            sev_icon = 'ğŸ”´' if sev == 'high' else 'ğŸŸ¡' if sev == 'medium' else 'ğŸŸ¢'
            md += f"\n### ğŸ” æ ¹å› åˆ†æ\n\n"
            md += f"**æ ¹å› :** {rca.get('root_cause', 'N/A')}\n"
            md += f"**ä¸¥é‡æ€§:** {sev_icon} {sev.upper()}\n"
            md += f"**ç½®ä¿¡åº¦:** {rca.get('confidence', 0):.0%}\n"
            md += f"**æ¨¡å‹:** `{rca.get('pattern_id', 'N/A')}`\n"
            
            evidence = rca.get('evidence', [])
            if evidence:
                md += "\n**è¯æ®:**\n"
                for e in evidence[:5]:
                    md += f"- {e}\n"
        
        # SOP Match
        if self.matched_sops:
            md += "\n### ğŸ› ï¸ æ¨è SOP\n\n"
            md += "| SOP | åç§° | é£é™© | åŒ¹é…åº¦ |\n|-----|------|------|--------|\n"
            for sop in self.matched_sops[:3]:
                md += f"| `{sop['sop_id']}` | {sop['name']} | {sop.get('risk_level', '?')} | {sop['match_confidence']:.0%} |\n"
        
        # Safety Check
        if self.safety_check:
            sc = self.safety_check
            md += f"\n### ğŸ›¡ï¸ å®‰å…¨æ£€æŸ¥\n\n"
            md += f"**é£é™©ç­‰çº§:** {sc.get('risk_level', '?')}\n"
            md += f"**æ‰§è¡Œæ¨¡å¼:** {sc.get('execution_mode', '?')}\n"
            md += f"**é€šè¿‡:** {'âœ…' if sc.get('passed') else 'âŒ'}\n"
        
        # Execution Result
        if self.execution_result:
            ex = self.execution_result
            md += f"\n### âš¡ æ‰§è¡Œç»“æœ\n\n"
            md += f"**SOP:** `{ex.get('sop_id', '?')}`\n"
            md += f"**ç»“æœ:** {'âœ… æˆåŠŸ' if ex.get('success') else 'âŒ å¤±è´¥'}\n"
            if ex.get('message'):
                md += f"**è¯¦æƒ…:** {ex['message']}\n"
        
        # Error
        if self.error:
            md += f"\n### âŒ é”™è¯¯\n\n```\n{self.error}\n```\n"
        
        return md


class IncidentOrchestrator:
    """
    Main orchestrator that connects all pipeline stages.
    
    Alert â†’ Collect (Step 1) â†’ Analyze (Step 2) â†’ Safety (Step 3) â†’ Execute â†’ Learn
    """
    
    def __init__(self, region: str = "ap-southeast-1"):
        self.region = region
        self._incidents: Dict[str, IncidentRecord] = {}
    
    async def handle_incident(
        self,
        trigger_type: str = "manual",
        trigger_data: Dict[str, Any] = None,
        services: List[str] = None,
        auto_execute: bool = False,
        dry_run: bool = False,
        force: bool = False,
        lookback_minutes: int = 15,
        pre_collected_event=None,
    ) -> IncidentRecord:
        """
        Full closed-loop incident handling pipeline.
        
        Args:
            trigger_type: alarm/anomaly/health_event/manual
            trigger_data: Raw trigger data
            services: Service filter for data collection
            auto_execute: Auto-execute matched SOPs
            dry_run: Preview only
            force: Override cooldowns
            pre_collected_event: Optional CorrelatedEvent from Detect Agent.
                When provided, Stage 1 (data collection) is skipped entirely,
                reusing the already-collected data. This avoids duplicate AWS
                API calls and aligns with the multi-agent architecture where
                Detect Agent owns data collection.
            
        Returns:
            IncidentRecord with full pipeline results
        """
        incident_id = f"inc-{uuid.uuid4().hex[:12]}"
        start_time = time.time()
        
        incident = IncidentRecord(
            incident_id=incident_id,
            trigger_type=TriggerType(trigger_type),
            trigger_data=trigger_data or {},
            region=self.region,
        )
        self._incidents[incident_id] = incident
        
        try:
            # â”€â”€ Stage 1: Data Collection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # If Detect Agent already collected data, reuse it (skip AWS calls).
            incident.status = IncidentStatus.COLLECTING
            stage_start = time.time()
            
            if pre_collected_event is not None:
                # Reuse Detect Agent's pre-collected CorrelatedEvent
                event = pre_collected_event
                logger.info(
                    f"[{incident_id}] Reusing pre-collected event "
                    f"{event.collection_id} â€” skipping Stage 1 collection"
                )
                incident.collection_summary = {
                    "collection_id": event.collection_id,
                    "metrics": len(event.metrics),
                    "alarms": len(event.alarms),
                    "trail_events": len(event.trail_events),
                    "anomalies": len(event.anomalies),
                    "health_events": len(event.health_events),
                    "duration_ms": event.duration_ms,
                    "source": "detect_agent_reuse",
                }
            else:
                # Fresh collection (manual trigger / no pre-collected data)
                from src.event_correlator import get_correlator
                correlator = get_correlator(self.region)
                
                event = await correlator.collect(
                    services=services,
                    lookback_minutes=lookback_minutes,
                )
                
                incident.collection_summary = {
                    "collection_id": event.collection_id,
                    "metrics": len(event.metrics),
                    "alarms": len(event.alarms),
                    "trail_events": len(event.trail_events),
                    "anomalies": len(event.anomalies),
                    "health_events": len(event.health_events),
                    "duration_ms": event.duration_ms,
                    "source": "fresh_collection",
                }
            
            incident.stage_timings["collect"] = int((time.time() - stage_start) * 1000)
            
            # â”€â”€ Stage 2: RCA Inference â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            incident.status = IncidentStatus.ANALYZING
            stage_start = time.time()
            
            from src.rca_inference import get_rca_inference_engine
            engine = get_rca_inference_engine()
            
            rca_result = await engine.analyze(event)
            
            incident.rca_result = rca_result.to_dict()
            incident.stage_timings["analyze"] = int((time.time() - stage_start) * 1000)
            
            # â”€â”€ Stage 3: SOP Matching â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            incident.status = IncidentStatus.SOP_MATCHED
            stage_start = time.time()
            
            from src.rca_sop_bridge import get_bridge
            bridge = get_bridge()
            
            # Match SOPs using the bridge (pass pre-computed RCA result)
            matched_sops = bridge.match_sops(rca_result)
            
            # Enrich with auto_execute policy
            for sop in matched_sops:
                sop_severity = sop.get('severity', 'medium')
                sop['auto_execute'] = (
                    sop_severity == 'low' and rca_result.confidence >= 0.8
                )
            incident.matched_sops = matched_sops
            incident.stage_timings["sop_match"] = int((time.time() - stage_start) * 1000)
            
            # â”€â”€ Stage 4: Safety Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if matched_sops:
                incident.status = IncidentStatus.SAFETY_CHECK
                stage_start = time.time()
                
                from src.sop_safety import get_safety_layer
                safety = get_safety_layer()
                
                best_sop = matched_sops[0]
                
                # Extract resource IDs from RCA
                # Prefer affected_resources from RCA, fallback to matched_symptoms
                resource_ids = (
                    getattr(rca_result, 'affected_resources', None)
                    or getattr(rca_result, 'matched_symptoms', None)
                    or []
                )
                
                safety_result = safety.check(
                    sop_id=best_sop['sop_id'],
                    resource_ids=resource_ids,
                    dry_run=dry_run,
                    force=force,
                    context={
                        "confidence": rca_result.confidence,
                        "severity": rca_result.severity.value if hasattr(rca_result.severity, 'value') else str(rca_result.severity),
                        "incident_id": incident_id,
                    },
                )
                
                # Enrich matched SOPs with risk level
                for sop in matched_sops:
                    sop['risk_level'] = safety._classify_risk(sop['sop_id']).value
                
                incident.safety_check = safety_result.to_dict()
                incident.stage_timings["safety_check"] = int((time.time() - stage_start) * 1000)
                
                # â”€â”€ Stage 5: Execute or Wait â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                if auto_execute and safety_result.passed and not dry_run:
                    incident.status = IncidentStatus.EXECUTING
                    stage_start = time.time()
                    
                    exec_result = self._execute_sop(
                        best_sop['sop_id'],
                        rca_result,
                        resource_ids,
                        safety,
                    )
                    
                    incident.execution_result = exec_result
                    incident.stage_timings["execute"] = int((time.time() - stage_start) * 1000)
                    
                elif safety_result.execution_mode == "approval":
                    incident.status = IncidentStatus.WAITING_APPROVAL
                    
                    # Create approval request
                    approval = safety.request_approval(
                        sop_id=best_sop['sop_id'],
                        context={
                            "incident_id": incident_id,
                            "root_cause": rca_result.root_cause,
                            "confidence": rca_result.confidence,
                        },
                    )
                    incident.execution_result = {
                        "action": "approval_requested",
                        "approval_id": approval.approval_id,
                        "sop_id": best_sop['sop_id'],
                        "message": f"éœ€è¦å®¡æ‰¹: {approval.approval_id}",
                    }
            
            # â”€â”€ Complete â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if incident.status not in (IncidentStatus.WAITING_APPROVAL,):
                incident.status = IncidentStatus.COMPLETED
            
            incident.completed_at = datetime.now(timezone.utc).isoformat()
            incident.duration_ms = int((time.time() - start_time) * 1000)
            
            # â”€â”€ Feedback Loop: Auto-learn from results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if incident.status == IncidentStatus.COMPLETED and matched_sops:
                self._auto_feedback(incident, rca_result, matched_sops)
            
            # â”€â”€ Persist incident record â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            self._persist_incident(incident)
            
            logger.info(
                f"Incident {incident_id} completed: {incident.status.value} "
                f"in {incident.duration_ms}ms"
            )
            
            return incident
            
        except Exception as e:
            incident.status = IncidentStatus.FAILED
            incident.error = str(e)
            incident.duration_ms = int((time.time() - start_time) * 1000)
            logger.error(f"Incident {incident_id} failed: {e}")
            return incident
    
    def _execute_sop(
        self,
        sop_id: str,
        rca_result,
        resource_ids: List[str],
        safety,
    ) -> Dict[str, Any]:
        """Execute a SOP with safety recording."""
        try:
            from src.sop_system import get_sop_executor
            
            executor = get_sop_executor()
            
            # Create snapshot before execution
            snapshot = safety.create_snapshot(
                sop_id=sop_id,
                resource_ids=resource_ids,
                pre_state={"rca_severity": rca_result.severity.value if hasattr(rca_result.severity, 'value') else str(rca_result.severity)},
            )
            
            # Execute
            execution = executor.start_execution(
                sop_id=sop_id,
                triggered_by="incident_orchestrator",
                context={
                    "rca_pattern_id": rca_result.pattern_id,
                    "root_cause": rca_result.root_cause,
                    "snapshot_id": snapshot.snapshot_id,
                },
            )
            
            # Record execution in safety layer
            safety.record_execution(sop_id, resource_ids)
            
            if execution:
                return {
                    "success": True,
                    "sop_id": sop_id,
                    "execution_id": execution.execution_id,
                    "snapshot_id": snapshot.snapshot_id,
                    "message": f"SOP {sop_id} å·²å¯åŠ¨",
                }
            else:
                return {
                    "success": False,
                    "sop_id": sop_id,
                    "message": "SOP executor returned None",
                }
        except Exception as e:
            return {
                "success": False,
                "sop_id": sop_id,
                "message": str(e),
            }
    
    def _auto_feedback(self, incident: IncidentRecord, rca_result, matched_sops):
        """Auto-generate feedback from completed incidents to strengthen patterns."""
        try:
            from src.rca_sop_bridge import get_bridge
            bridge = get_bridge()
            
            pattern_id = rca_result.pattern_id
            
            # If execution happened and succeeded, submit positive feedback
            if incident.execution_result and incident.execution_result.get('success'):
                sop_id = incident.execution_result.get('sop_id', '')
                bridge.submit_feedback(
                    execution_id=incident.execution_result.get('execution_id', incident.incident_id),
                    sop_id=sop_id,
                    rca_pattern_id=pattern_id,
                    success=True,
                    root_cause_confirmed=rca_result.confidence >= 0.8,
                    resolution_time_seconds=int(incident.duration_ms / 1000),
                    notes=f"Auto-feedback from incident {incident.incident_id}",
                )
                logger.info(f"Auto-feedback: {pattern_id} â†’ {sop_id} (success)")
            
            # Even without execution, strengthen the patternâ†”SOP mapping
            # if high confidence and SOPs were matched
            elif rca_result.confidence >= 0.85 and matched_sops:
                best_sop = matched_sops[0]
                bridge.submit_feedback(
                    execution_id=incident.incident_id,
                    sop_id=best_sop['sop_id'],
                    rca_pattern_id=pattern_id,
                    success=True,  # High-confidence match = implicit positive signal
                    root_cause_confirmed=False,
                    notes=f"High-confidence match ({rca_result.confidence:.0%}), no execution",
                )
                logger.info(f"Auto-feedback (match only): {pattern_id} â†’ {best_sop['sop_id']}")
        except Exception as e:
            logger.warning(f"Auto-feedback failed: {e}")
    
    def _persist_incident(self, incident: IncidentRecord):
        """Persist incident record to local JSON file."""
        try:
            import json
            import os
            
            persist_dir = os.path.join(os.path.dirname(__file__), '..', 'data', 'incidents')
            os.makedirs(persist_dir, exist_ok=True)
            
            filepath = os.path.join(persist_dir, f"{incident.incident_id}.json")
            with open(filepath, 'w') as f:
                json.dump(incident.to_dict(), f, indent=2, default=str)
            
            logger.info(f"Persisted incident {incident.incident_id} to {filepath}")
        except Exception as e:
            logger.warning(f"Failed to persist incident: {e}")
    
    def get_incident(self, incident_id: str) -> Optional[IncidentRecord]:
        """Get an incident by ID."""
        return self._incidents.get(incident_id)
    
    def list_incidents(self, limit: int = 20, status: str = None) -> List[Dict[str, Any]]:
        """List recent incidents."""
        incidents = list(self._incidents.values())
        
        if status:
            incidents = [i for i in incidents if i.status.value == status]
        
        incidents.sort(key=lambda x: x.created_at, reverse=True)
        return [i.to_dict() for i in incidents[:limit]]
    
    def get_stats(self) -> Dict[str, Any]:
        """Get orchestrator statistics."""
        incidents = list(self._incidents.values())
        
        by_status = {}
        for i in incidents:
            by_status[i.status.value] = by_status.get(i.status.value, 0) + 1
        
        completed = [i for i in incidents if i.status == IncidentStatus.COMPLETED]
        avg_duration = (
            sum(i.duration_ms for i in completed) / len(completed)
            if completed else 0
        )
        
        # Average stage timings
        avg_stages = {}
        for i in completed:
            for stage, ms in i.stage_timings.items():
                if stage not in avg_stages:
                    avg_stages[stage] = []
                avg_stages[stage].append(ms)
        
        avg_stages = {
            stage: int(sum(times) / len(times))
            for stage, times in avg_stages.items()
        }
        
        return {
            "total_incidents": len(incidents),
            "by_status": by_status,
            "avg_duration_ms": int(avg_duration),
            "avg_stage_timings": avg_stages,
            "target_ms": 25000,
            "within_target": avg_duration <= 25000 if completed else True,
        }


# =============================================================================
# Singleton
# =============================================================================

_orchestrator: Optional[IncidentOrchestrator] = None


def get_orchestrator(region: str = "ap-southeast-1") -> IncidentOrchestrator:
    """Get or create the incident orchestrator singleton."""
    global _orchestrator
    if _orchestrator is None:
        _orchestrator = IncidentOrchestrator(region=region)
    return _orchestrator
